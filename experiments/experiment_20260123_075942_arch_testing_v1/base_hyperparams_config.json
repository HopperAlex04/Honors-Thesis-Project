{
  "comment": "Hyperparameter configuration for training DQN agent in Cuttle game.",
  "random_seed": 15796,
  "comment_random_seed": "Seed for reproducibility. Set to null for non-deterministic runs. Experiment manager overrides this.",
  "network_type": "game_based",
  "comment_network_type": "Options: 'linear' (no hidden layers), 'large_hidden' (1024 neurons), 'game_based' (hierarchical [52,13,15]). Backward compatible: 'boolean', 'embedding', 'multi_encoder'",
  "game_based_scale": 1,
  "comment_game_based_scale": "Scale factor for game-based architecture. When set, uses [52*k, 13*k, 15*k] hidden layers. Used by scaling experiment to surpass large_hidden baseline.",
  "game_based_hidden_layers": null,
  "comment_game_based_hidden_layers": "Optional explicit game-based hidden layer sizes (list of ints). If null, uses [52*scale, 13*scale, 15*scale]. Example: [104, 26, 30] for 2x scaling.",
  "embedding_dim": 32,
  "comment_embedding_dim": "For embedding-based network only (backward compatibility)",
  "embedding_size": 16,
  "comment_embedding_size": "Kept for backward compatibility, no longer used (no embeddings - all inputs are boolean arrays)",
  "batch_size": 128,
  "gamma": 0.9,
  "eps_start": 0.9,
  "eps_end": 0.15,
  "eps_decay": 20000,
  "eps_decay_comment": "Decay constant for epsilon-greedy. Adjusted for ~34,000 total training steps. Epsilon decays from 0.9 to ~0.1 over full training, allowing gradual exploration-to-exploitation transition. Previous value (1500) caused epsilon to reach minimum too early (round 5).",
  "tau": 0.005,
  "target_update_frequency": 500,
  "learning_rate": 5e-5,
  "learning_rate_comment": "Reduced from 1e-4 to 3e-5 for more stable learning. Model was learning (loss decreasing) but not improving performance, suggesting unstable updates. Quick test mode enabled for debugging.",
  "lr_decay_rate": 0.9,
  "lr_decay_interval": 5,
  "gradient_clip_norm": 5.0,
  "q_value_clip": 15.0,
  "replay_buffer_size": 30000,
  "training": {
    "rounds": 20,
    "eps_per_round": 250,
    "quick_test_mode": true,
    "quick_test_mode_comment": "Enabled for debugging. Running 5 rounds with 100 episodes each to quickly test if learning rate reduction improves performance.",
    "quick_test_rounds": 5,
    "quick_test_eps_per_round": 250,
    "validation_episodes_ratio": 1.0,
    "validation_episodes_ratio_comment": "250 validation episodes per round for reliable win rate estimates. Time saved by reducing runs per type from 7 to 5 instead.",
    "validation_opponent": "both",
    "validation_opponent_comment": "Options: 'randomized', 'gapmaximizer', or 'both'"
  },
  "early_stopping": {
    "enabled": true,
    "check_interval": 50,
    "window_size": 100,
    "divergence_threshold": 0.5,
    "min_episodes": 200,
    "max_loss": 50.0
  }
}